{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STA 141B Final Project\n",
    "\n",
    "Our current president loves to talk about climate change. While President Trump's tweets have lately been more focused on what might consider to be more pressing matters for his administration, Trump has publicly expressed his opinions on climate science no less than 145 times in the past 6 years. \n",
    "\n",
    "President Trump's twitter behavior is characterized by two key aspects:\n",
    "\n",
    "1. There's a seasonal pattern to President Trump's tweets. He appears to focus on climate change when weather is cold.\n",
    "\n",
    "2. President Trump likes to use the term \"global warming\", which misrepresents the phenomenon of climate change.\n",
    "\n",
    "__Are these patterns of behavior unique, or representative of general trends?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Some Examples:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">\n",
       "The concept of global warming was created by and for the Chinese in order to make U.S. \n",
       "manufacturing non-competitive.</p>&mdash; Donald J. Trump (@realDonaldTrump) \n",
       "<a href=\"https://twitter.com/realDonaldTrump/status/265895292191248385?ref_src=twsrc%5Etfw\">November 6, 2012</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<__main__.Tweet at 0x23d08f4ddd8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Tweet(object):\n",
    "    def __init__(self, embed_str=None):\n",
    "        self.embed_str = embed_str\n",
    "    def _repr_html_(self):\n",
    "        return self.embed_str\n",
    "    \n",
    "address = (\"\"\"\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">\n",
    "The concept of global warming was created by and for the Chinese in order to make U.S. \n",
    "manufacturing non-competitive.</p>&mdash; Donald J. Trump (@realDonaldTrump) \n",
    "<a href=\"https://twitter.com/realDonaldTrump/status/265895292191248385?ref_src=twsrc%5Etfw\">November 6, 2012</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\"\"\")\n",
    "\n",
    "Tweet(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">\n",
       "In the East, it could be the COLDEST New Year’s Eve on record. \n",
       "Perhaps we could use a little bit of that good old Global Warming that our Country, \n",
       "but not other countries, was going to pay TRILLIONS OF DOLLARS to protect against. Bundle up!\n",
       "</p>&mdash; Donald J. Trump (@realDonaldTrump) \n",
       "<a href=\"https://twitter.com/realDonaldTrump/status/946531657229701120?ref_src=twsrc%5Etfw\">\n",
       "December 29, 2017</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<__main__.Tweet at 0x23d08f704a8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = (\"\"\"\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">\n",
    "In the East, it could be the COLDEST New Year’s Eve on record. \n",
    "Perhaps we could use a little bit of that good old Global Warming that our Country, \n",
    "but not other countries, was going to pay TRILLIONS OF DOLLARS to protect against. Bundle up!\n",
    "</p>&mdash; Donald J. Trump (@realDonaldTrump) \n",
    "<a href=\"https://twitter.com/realDonaldTrump/status/946531657229701120?ref_src=twsrc%5Etfw\">\n",
    "December 29, 2017</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\"\"\")\n",
    "\n",
    "Tweet(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__In this project, I want to address two key questions:__\n",
    "\n",
    "1. Are there seasonal patterns in public interest towards climate change / global warming?\n",
    "\n",
    "2. Does the use of the terms \"climate change\" and \"global warming\" correlate with attitudes towards climate science? Are those who attempt to cast doubt on climate research more likely to use the term \"global warming\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Question 1. Are there seasonal patterns in public interest towards climate change / global warming?__\n",
    "\n",
    "To address this question, I will use two datasets:\n",
    "\n",
    "1. Google Trends: 10 years of data on the frequency of US Google searches for the terms \"climate change\" and \"global warming\".\n",
    "\n",
    "2. US Mean Monthly Temperature: NOAA data product containing average monthly temperature readings across all climate monitoring stations across the United States.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebatz\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning:\n",
      "\n",
      "The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import statsmodels\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import statsmodels.api as sm\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "\n",
    "plotly.tools.set_credentials_file(username='ebatzer', api_key='BIJOCGPZqKooZ16thhcw')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "gtrends = pd.read_csv(\"googletrends.csv\")\n",
    "gtrends.columns = [\"month\", \"climate change\", \"global warming\"]\n",
    "gtrends[\"month\"] = gtrends[\"month\"] + \"/01\"\n",
    "gtrends[\"date_num\"] = pd.to_datetime(gtrends[\"month\"], yearfirst = True)\n",
    "gtrends[\"total\"] = gtrends[\"climate change\"] + gtrends[\"global warming\"]\n",
    "gtrends[\"total\"] = (gtrends[\"total\"] / max(gtrends[\"total\"])) * 100\n",
    "\n",
    "# Create traces\n",
    "data = Data([\n",
    "    Scatter(\n",
    "        y = gtrends[\"global warming\"],\n",
    "        x = gtrends[\"date_num\"],\n",
    "        marker=Line(\n",
    "            color = \"red\"\n",
    "        ),\n",
    "        mode='lines',\n",
    "        name = 'Global Warming',\n",
    "        showlegend = True),\n",
    "    Scatter(\n",
    "        y = gtrends[\"climate change\"],\n",
    "        x = gtrends[\"date_num\"],\n",
    "        marker=Line(\n",
    "            color = \"blue\"\n",
    "        ),\n",
    "        mode='lines',\n",
    "        name = 'Climate Change',\n",
    "        showlegend = True)\n",
    "])\n",
    "\n",
    "layout = Layout(\n",
    "    title='Google Searches for \"Climate Change\" and \"Global Warming\"',\n",
    "    xaxis=dict(\n",
    "        title='Date',\n",
    "        titlefont=dict(\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        ),\n",
    "        showgrid=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Frequency',\n",
    "        titlefont=dict(\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        ),\n",
    "        showgrid=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = Figure(data = data, layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ebatzer/346.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"NOAAweatherdata.csv\", skiprows = 4) \n",
    "weather[\"Month\"] = weather[\"Date\"] % 100\n",
    "weather[\"Year\"] = weather[\"Date\"].apply(str).apply(lambda x: x[:4])\n",
    "weather[\"Date\"] = weather[\"Year\"] + \"/\" + weather[\"Month\"].apply(str) + \"/01\"\n",
    "weather[\"date_num\"] = pd.to_datetime(weather[\"Date\"], yearfirst = True)\n",
    "gtrends = pd.merge(gtrends, weather, \"inner\")\n",
    "\n",
    "lowess = sm.nonparametric.lowess\n",
    "ys = lowess( gtrends[\"total\"], pd.to_numeric(gtrends[\"date_num\"]), frac = .3)[:,1]\n",
    "gtrends['polyfit'] = ys\n",
    "gtrends['resid'] = gtrends[\"total\"] - gtrends['polyfit']\n",
    "\n",
    "# Create traces\n",
    "data = Data([\n",
    "    Scatter(\n",
    "        y = gtrends[\"total\"],\n",
    "        x = gtrends[\"date_num\"],\n",
    "        marker=Marker(\n",
    "            size=12,\n",
    "            cmax=80,\n",
    "            cmin=30,\n",
    "            color= gtrends[\"Value\"],\n",
    "            colorbar=ColorBar(\n",
    "                title='Mean US Temperature'\n",
    "            ),\n",
    "            colorscale='Viridis'\n",
    "        ),\n",
    "        mode='lines+markers',\n",
    "        showlegend = False),\n",
    "    Scatter(\n",
    "        y= gtrends[\"polyfit\"],\n",
    "        x = gtrends[\"date_num\"],\n",
    "        line=Line(\n",
    "            color= \"black\"),\n",
    "        mode='lines',\n",
    "        showlegend = False),\n",
    "])\n",
    "\n",
    "layout = Layout(\n",
    "    title='Google Searches for \"Climate Change\" and \"Global Warming\"',\n",
    "    xaxis=dict(\n",
    "        title='Date',\n",
    "        titlefont=dict(\n",
    "            size=18,\n",
    "            color='#7f7f7f'),\n",
    "        showgrid=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Frequency',\n",
    "        titlefont=dict(\n",
    "            size=18,\n",
    "            color='#7f7f7f'),\n",
    "        showgrid=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = Figure(data = data, layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ebatzer/348.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "gore_lines = [\"2006-05-24\",\"2007-02-26\",\"2007-10-12\"]\n",
    "labels = ['\"An Incovenient Truth\" Released', 'AIT Wins Best Documentary', 'Al Gore and IPCC win Nobel']\n",
    "\n",
    "# Create traces\n",
    "data = Data([\n",
    "            Scatter(\n",
    "                y = gtrends[\"total\"],\n",
    "                x = gtrends[\"date_num\"],\n",
    "                marker=Marker(\n",
    "                    size=12,\n",
    "                    cmax=80,\n",
    "                    cmin=30,\n",
    "                    color= gtrends[\"Value\"],\n",
    "                    colorbar=ColorBar(\n",
    "                        title='Mean US Temperature'\n",
    "                    ),\n",
    "                    colorscale='Viridis'\n",
    "                ),\n",
    "                mode='lines+markers',\n",
    "                showlegend = False),\n",
    "            Scatter(\n",
    "                y= gtrends[\"polyfit\"],\n",
    "                x = gtrends[\"date_num\"],\n",
    "                line=Line(\n",
    "                    color= \"black\"),\n",
    "                mode='lines',\n",
    "                showlegend = False),\n",
    "            Scatter(\n",
    "                y = [0, 100],\n",
    "                x = [gore_lines[0], gore_lines[0]],\n",
    "                mode = \"lines\",\n",
    "                line = Line(color = \"red\"),\n",
    "                showlegend = False),\n",
    "            Scatter(\n",
    "                y = [0, 100],\n",
    "                x = [gore_lines[1], gore_lines[1]],\n",
    "                mode = \"lines\",\n",
    "                line = Line(color = \"red\"),\n",
    "                showlegend = False),\n",
    "            Scatter(\n",
    "                y = [0, 100],\n",
    "                x = [gore_lines[2], gore_lines[2]],\n",
    "                mode = \"lines\",\n",
    "                line = Line(color = \"red\"),\n",
    "                showlegend = False)\n",
    "])\n",
    "\n",
    "annotations = []\n",
    "\n",
    "for label, xval, yadj in zip(labels, gore_lines, [0, 20, 40]):\n",
    "    annotations.append(dict( x=xval, y=100, ay = -yadj,\n",
    "                                      xanchor='right', yanchor='middle',\n",
    "                                      text=label,\n",
    "                                      font=dict(family='Arial',\n",
    "                                                size=16),\n",
    "                                      showarrow=True))\n",
    "    \n",
    "layout[\"annotations\"] = annotations\n",
    "fig = Figure(data = data, layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ebatzer/350.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "f = np.poly1d(np.polyfit(gtrends[\"Value\"], gtrends[\"resid\"], 2))\n",
    "predseq = np.linspace(30,80).tolist()\n",
    "quadfit = f(predseq)\n",
    "\n",
    "# Create traces\n",
    "data = Data([\n",
    "    Scatter(\n",
    "        y= gtrends[\"resid\"],\n",
    "        x= gtrends[\"Value\"],\n",
    "        marker=Marker(\n",
    "            size=12,\n",
    "            cmax=80,\n",
    "            cmin=0,\n",
    "            color=  gtrends[\"Value\"],\n",
    "            colorbar=ColorBar(\n",
    "                title='Temperature (F)'\n",
    "            ),\n",
    "            colorscale='Viridis'\n",
    "        ),\n",
    "        mode='markers',\n",
    "        showlegend = False),\n",
    "    Scatter(\n",
    "        y = quadfit,\n",
    "        x = predseq,\n",
    "        line=Line(\n",
    "            color= \"black\"),\n",
    "        mode='lines',\n",
    "        showlegend = False)\n",
    "])\n",
    "\n",
    "\n",
    "layout = Layout(\n",
    "    title='LOWESS Residuals',\n",
    "    xaxis=dict(\n",
    "        title='Mean US Temperature',\n",
    "        titlefont=dict(\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        ),\n",
    "        showgrid=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Residuals',\n",
    "        titlefont=dict(\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        ),\n",
    "        showgrid=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = Figure(data = data, layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ebatzer/352.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Question 2: Does the use of the terms \"climate change\" and \"global warming\" correlate with attitudes towards climate science?__\n",
    "\n",
    "Dataset: Reddit submissions containing the terms \"climate change\" and \"global warming\"\n",
    "\n",
    "- Reddit: A content aggregator containing user submitted photos, links, and text posts in distinct communities (forums).\n",
    "\n",
    "\n",
    "- Queried API to retrieve all relevant submissions from January 1st, 2018 to the present, written into an SQL database.\n",
    "\n",
    "\n",
    "- Resulting dataset contains ~300,000 unique submissions with information on title, community (subreddit), date posted, community score, submission link, submission domain, etc.\n",
    "\n",
    "Currently, I'm trying to explore this dataset to better understand features of the userbase and forum activity that may influence subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests_cache\n",
    "import time\n",
    "\n",
    "requests_cache.install_cache('reddit_cache')\n",
    "\n",
    "url = \"https://api.pushshift.io/reddit/search/submission/\"\n",
    "\n",
    "# Sets dates - will run for all days between start and end\n",
    "dstart = datetime.date(2008, 1, 1)\n",
    "dend = datetime.date(2018, 1, 1)\n",
    "steps = (dend - dstart).days\n",
    "\n",
    "# Sets timesteps (start date, the first timestep, and the size between them, in epochs)\n",
    "t0 = pd.to_numeric(time.mktime(time.strptime(\"2008/01/01 00:00:00 GMT\", \"%Y/%m/%d %H:%M:%S %Z\")))\n",
    "t1 = pd.to_numeric(time.mktime(time.strptime(\"2018/01/01 00:00:00 GMT\", \"%Y/%m/%d %H:%M:%S %Z\")))\n",
    "\n",
    "# Define the search subs function:\n",
    "def search_subs(url, searchterm, sub, size, after, before):\n",
    "    \n",
    "    # Requests PushShift API\n",
    "    req = requests.get(url, params = {\"title\" : searchterm,\n",
    "                                     \"after\": after,\n",
    "                                     \"before\": before,\n",
    "                                     \"subreddit\": sub,\n",
    "                                     \"size\": size})\n",
    "\n",
    "    # Selects data element\n",
    "    subdata = pd.DataFrame(req.json()['data'])\n",
    "    \n",
    "    # Adds identifying columns\n",
    "    subdata[\"searchstart\"] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(after))\n",
    "    subdata[\"searchend\"] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(before))\n",
    "    subdata[\"keyword\"] = searchterm\n",
    "    \n",
    "    return(subdata, subdata[\"created_utc\"].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('sqlite:///subs.db')\n",
    "\n",
    "# search_utc = int(t0)\n",
    "# outputdf = dict()\n",
    "# count = 1\n",
    "\n",
    "# while search_utc < int(t1) :\n",
    "#     subs, search_utc = search_subs( \n",
    "#             url = url, \n",
    "#             searchterm = \"climate change\", \n",
    "#             sub = None, \n",
    "#             after = search_utc,\n",
    "#             before = None,\n",
    "#             size = 500)\n",
    "    \n",
    "#     cols = [\"author\", \"created_utc\", \"domain\", \"id\", \"num_comments\",\n",
    "#            \"permalink\", \"score\", \"subreddit\", \"subreddit_id\",\n",
    "#            \"title\", \"url\", \"searchstart\", \"searchend\", \"keyword\"]\n",
    "#     subs = subs[cols]\n",
    "#     subs.to_sql(\"cctable\", engine, if_exists = \"append\")\n",
    "    \n",
    "#     search_utc = search_utc + 1\n",
    "\n",
    "#     if count % 25 == 0:\n",
    "#         print(\"Current time is %s\" % time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "#                                                    time.localtime(search_utc)))\n",
    "        \n",
    "#     count = count + 1\n",
    "      \n",
    "#     # Sleep to avoid over-requesting\n",
    "#     time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# search_utc = int(t0)\n",
    "# outputdf = dict()\n",
    "# count = 1\n",
    "\n",
    "# while search_utc < int(t1) :\n",
    "#     subs, search_utc = search_subs( \n",
    "#             url = url, \n",
    "#             searchterm = \"global warming\", \n",
    "#             sub = None, \n",
    "#             after = search_utc,\n",
    "#             before = None,\n",
    "#             size = 500)\n",
    "    \n",
    "#     cols = [\"author\", \"created_utc\", \"domain\", \"id\", \"num_comments\",\n",
    "#            \"permalink\", \"score\", \"subreddit\", \"subreddit_id\",\n",
    "#            \"title\", \"url\", \"searchstart\", \"searchend\", \"keyword\"]\n",
    "#     subs = subs[cols]\n",
    "#     subs.to_sql(\"gwtable\", engine, if_exists = \"append\")\n",
    "    \n",
    "#     search_utc = search_utc + 1\n",
    "\n",
    "#     if count % 25 == 0:\n",
    "#         print(\"Current time is %s\" % time.strftime('%Y-%m-%d %H:%M:%S',\n",
    "#                                                    time.localtime(search_utc)))\n",
    "        \n",
    "#     count = count + 1\n",
    "      \n",
    "#     # Sleep to avoid over-requesting\n",
    "#     time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "gwcounts = pd.read_sql(\"\"\"SELECT subreddit, COUNT(subreddit) \n",
    "FROM gwtable\n",
    "GROUP BY subreddit\n",
    "ORDER BY COUNT(subreddit) DESC\n",
    "\"\"\",\n",
    "               con = engine)\n",
    "\n",
    "cccounts = pd.read_sql(\"\"\"SELECT subreddit, COUNT(subreddit) \n",
    "FROM cctable\n",
    "GROUP BY subreddit\n",
    "ORDER BY COUNT(subreddit) DESC\n",
    "\"\"\",\n",
    "               con = engine)\n",
    "\n",
    "authors = pd.read_sql(\"\"\"SELECT subreddit, COUNT(DISTINCT author) \n",
    "FROM gwtable\n",
    "GROUP BY subreddit\n",
    "ORDER BY COUNT(DISTINCT author) DESC\n",
    "\"\"\",\n",
    "               con = engine)\n",
    "\n",
    "#################################\n",
    "# Some basic summary statistics #\n",
    "#################################\n",
    "\n",
    "gwcounts.columns = ['subreddit', 'gw_counts']\n",
    "cccounts.columns = ['subreddit', 'cc_counts']\n",
    "authors.columns = ['subreddit', 'authors']\n",
    "\n",
    "keywords = pd.merge(gwcounts, cccounts)\n",
    "keywords = pd.merge(keywords, authors)\n",
    "\n",
    "keywords[\"total\"] = keywords[\"cc_counts\"] + keywords[\"gw_counts\"]\n",
    "keywords[\"gw_frac\"] = keywords[\"gw_counts\"] / keywords[\"total\"]\n",
    "keywords[\"cc_frac\"] = keywords[\"cc_counts\"] / keywords[\"total\"]\n",
    "keywords[\"aut_frac\"] = keywords[\"authors\"] / keywords[\"total\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Are submissions equally divided across different communities?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]  [ (1,3) x3,y3 ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebatz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\ebatz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\ebatz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trace1 = Scatter(\n",
    "    x=keywords.sort_values(\"total\", ascending = False)[\"subreddit\"],\n",
    "    y=np.log(keywords.sort_values(\"total\", ascending = False)[\"total\"]),\n",
    "    name = \"Total\"\n",
    ")\n",
    "\n",
    "trace2 = Scatter(\n",
    "    x=keywords.sort_values(\"cc_counts\", ascending = False)[\"subreddit\"],\n",
    "    y=np.log(keywords.sort_values(\"cc_counts\", ascending = False)[\"cc_counts\"]),\n",
    "    name = \"Climate Change\"\n",
    ")\n",
    "\n",
    "trace3 = Scatter(\n",
    "    x=keywords.sort_values(\"gw_counts\", ascending = False)[\"subreddit\"],\n",
    "    y=np.log(keywords.sort_values(\"gw_counts\", ascending = False)[\"gw_counts\"]),\n",
    "    name = \"Global Warming\"\n",
    ")\n",
    "\n",
    "fig = plotly.tools.make_subplots(rows=1, cols=3)\n",
    "\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 1, 2)\n",
    "fig.append_trace(trace3, 1, 3)\n",
    "\n",
    "\n",
    "fig['layout'].update(height=600, width=600, title='Total keyword mentions (log scale)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ebatzer/248.embed\" height=\"600px\" width=\"600px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig, filename='simple-subplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>gw_counts</th>\n",
       "      <th>cc_counts</th>\n",
       "      <th>authors</th>\n",
       "      <th>total</th>\n",
       "      <th>gw_frac</th>\n",
       "      <th>cc_frac</th>\n",
       "      <th>aut_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>environment</td>\n",
       "      <td>6876</td>\n",
       "      <td>22549</td>\n",
       "      <td>2109</td>\n",
       "      <td>29425</td>\n",
       "      <td>0.233679</td>\n",
       "      <td>0.766321</td>\n",
       "      <td>0.071674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EcoInternet</td>\n",
       "      <td>1586</td>\n",
       "      <td>17293</td>\n",
       "      <td>2</td>\n",
       "      <td>18879</td>\n",
       "      <td>0.084009</td>\n",
       "      <td>0.915991</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>4343</td>\n",
       "      <td>12488</td>\n",
       "      <td>1800</td>\n",
       "      <td>16831</td>\n",
       "      <td>0.258036</td>\n",
       "      <td>0.741964</td>\n",
       "      <td>0.106946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>climate</td>\n",
       "      <td>2357</td>\n",
       "      <td>9978</td>\n",
       "      <td>469</td>\n",
       "      <td>12335</td>\n",
       "      <td>0.191082</td>\n",
       "      <td>0.808918</td>\n",
       "      <td>0.038022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reddit.com</td>\n",
       "      <td>4148</td>\n",
       "      <td>7340</td>\n",
       "      <td>2316</td>\n",
       "      <td>11488</td>\n",
       "      <td>0.361072</td>\n",
       "      <td>0.638928</td>\n",
       "      <td>0.201602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>4047</td>\n",
       "      <td>6955</td>\n",
       "      <td>1981</td>\n",
       "      <td>11002</td>\n",
       "      <td>0.367842</td>\n",
       "      <td>0.632158</td>\n",
       "      <td>0.180058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>4374</td>\n",
       "      <td>4626</td>\n",
       "      <td>526</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.058444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>2046</td>\n",
       "      <td>6026</td>\n",
       "      <td>960</td>\n",
       "      <td>8072</td>\n",
       "      <td>0.253469</td>\n",
       "      <td>0.746531</td>\n",
       "      <td>0.118930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>POLITIC</td>\n",
       "      <td>2072</td>\n",
       "      <td>4916</td>\n",
       "      <td>36</td>\n",
       "      <td>6988</td>\n",
       "      <td>0.296508</td>\n",
       "      <td>0.703492</td>\n",
       "      <td>0.005152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2811</td>\n",
       "      <td>4107</td>\n",
       "      <td>1784</td>\n",
       "      <td>6918</td>\n",
       "      <td>0.406331</td>\n",
       "      <td>0.593669</td>\n",
       "      <td>0.257878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit  gw_counts  cc_counts  authors  total   gw_frac   cc_frac  \\\n",
       "0       environment       6876      22549     2109  29425  0.233679  0.766321   \n",
       "12      EcoInternet       1586      17293        2  18879  0.084009  0.915991   \n",
       "2          politics       4343      12488     1800  16831  0.258036  0.741964   \n",
       "7           climate       2357       9978      469  12335  0.191082  0.808918   \n",
       "3        reddit.com       4148       7340     2316  11488  0.361072  0.638928   \n",
       "4           science       4047       6955     1981  11002  0.367842  0.632158   \n",
       "1   climateskeptics       4374       4626      526   9000  0.486000  0.514000   \n",
       "10        worldnews       2046       6026      960   8072  0.253469  0.746531   \n",
       "8           POLITIC       2072       4916       36   6988  0.296508  0.703492   \n",
       "6         AskReddit       2811       4107     1784   6918  0.406331  0.593669   \n",
       "\n",
       "    aut_frac  \n",
       "0   0.071674  \n",
       "12  0.000106  \n",
       "2   0.106946  \n",
       "7   0.038022  \n",
       "3   0.201602  \n",
       "4   0.180058  \n",
       "1   0.058444  \n",
       "10  0.118930  \n",
       "8   0.005152  \n",
       "6   0.257878  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords.sort_values(\"total\", ascending = False).iloc[:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Are certain communities dominated by small numbers of users?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebatz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\ebatz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\ebatz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create traces\n",
    "data = Data([\n",
    "    Scatter(\n",
    "        y= np.log(keywords.sort_values(\"total\", ascending = False)[\"total\"]),\n",
    "        x= np.log(keywords.sort_values(\"total\", ascending = False)[\"authors\"]),\n",
    "        marker=Marker(\n",
    "            size= np.log(keywords.sort_values(\"total\", ascending = False)[\"total\"]) * 2,\n",
    "            cmax=1,\n",
    "            cmin=0,\n",
    "            color= keywords.sort_values(\"total\", ascending = False)[\"cc_frac\"],\n",
    "            colorbar=ColorBar(\n",
    "                title='Climate Change Fraction'\n",
    "            ),\n",
    "            colorscale='Viridis'\n",
    "        ),\n",
    "        mode='markers',\n",
    "        name='Markers',\n",
    "        text=keywords.sort_values(\"total\", ascending = False)[\"subreddit\"],\n",
    "        textposition='bottom',\n",
    "        showlegend = False)\n",
    "])\n",
    "\n",
    "\n",
    "layout = Layout(\n",
    "    title='Activity vs. Unique Number of Authors',\n",
    "    xaxis=dict(\n",
    "        title='Total Unique Authors (log scale)',\n",
    "        titlefont=dict(\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        ),\n",
    "        showgrid=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Total Number of Posts (log scale)',\n",
    "        titlefont=dict(\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        ),\n",
    "        showgrid=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = Figure(data = data, layout = layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ebatzer/354.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Which communities talk about climate change the most? Which communities talk about global warming the most?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>gw_counts</th>\n",
       "      <th>cc_counts</th>\n",
       "      <th>authors</th>\n",
       "      <th>total</th>\n",
       "      <th>gw_frac</th>\n",
       "      <th>cc_frac</th>\n",
       "      <th>aut_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>climatechange</td>\n",
       "      <td>383</td>\n",
       "      <td>1884</td>\n",
       "      <td>190</td>\n",
       "      <td>2267</td>\n",
       "      <td>0.168946</td>\n",
       "      <td>0.831054</td>\n",
       "      <td>0.083811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>climate</td>\n",
       "      <td>2357</td>\n",
       "      <td>9978</td>\n",
       "      <td>469</td>\n",
       "      <td>12335</td>\n",
       "      <td>0.191082</td>\n",
       "      <td>0.808918</td>\n",
       "      <td>0.038022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>collapse</td>\n",
       "      <td>512</td>\n",
       "      <td>1904</td>\n",
       "      <td>172</td>\n",
       "      <td>2416</td>\n",
       "      <td>0.211921</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.071192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>environment</td>\n",
       "      <td>6876</td>\n",
       "      <td>22549</td>\n",
       "      <td>2109</td>\n",
       "      <td>29425</td>\n",
       "      <td>0.233679</td>\n",
       "      <td>0.766321</td>\n",
       "      <td>0.071674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>2046</td>\n",
       "      <td>6026</td>\n",
       "      <td>960</td>\n",
       "      <td>8072</td>\n",
       "      <td>0.253469</td>\n",
       "      <td>0.746531</td>\n",
       "      <td>0.118930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit  gw_counts  cc_counts  authors  total   gw_frac   cc_frac  \\\n",
       "31  climatechange        383       1884      190   2267  0.168946  0.831054   \n",
       "7         climate       2357       9978      469  12335  0.191082  0.808918   \n",
       "27       collapse        512       1904      172   2416  0.211921  0.788079   \n",
       "0     environment       6876      22549     2109  29425  0.233679  0.766321   \n",
       "10      worldnews       2046       6026      960   8072  0.253469  0.746531   \n",
       "\n",
       "    aut_frac  \n",
       "31  0.083811  \n",
       "7   0.038022  \n",
       "27  0.071192  \n",
       "0   0.071674  \n",
       "10  0.118930  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cctop5 = keywords[(keywords[\"total\"] > 2000) & (keywords[\"aut_frac\"] > .01)].sort_values(\"cc_frac\", ascending = False).iloc[:5,]\n",
    "cctop5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>gw_counts</th>\n",
       "      <th>cc_counts</th>\n",
       "      <th>authors</th>\n",
       "      <th>total</th>\n",
       "      <th>gw_frac</th>\n",
       "      <th>cc_frac</th>\n",
       "      <th>aut_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1897</td>\n",
       "      <td>1644</td>\n",
       "      <td>1340</td>\n",
       "      <td>3541</td>\n",
       "      <td>0.535724</td>\n",
       "      <td>0.464276</td>\n",
       "      <td>0.378424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>4374</td>\n",
       "      <td>4626</td>\n",
       "      <td>526</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.058444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>1338</td>\n",
       "      <td>1462</td>\n",
       "      <td>512</td>\n",
       "      <td>2800</td>\n",
       "      <td>0.477857</td>\n",
       "      <td>0.522143</td>\n",
       "      <td>0.182857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>askscience</td>\n",
       "      <td>2887</td>\n",
       "      <td>3190</td>\n",
       "      <td>1958</td>\n",
       "      <td>6077</td>\n",
       "      <td>0.475070</td>\n",
       "      <td>0.524930</td>\n",
       "      <td>0.322198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>1090</td>\n",
       "      <td>1226</td>\n",
       "      <td>785</td>\n",
       "      <td>2316</td>\n",
       "      <td>0.470639</td>\n",
       "      <td>0.529361</td>\n",
       "      <td>0.338946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subreddit  gw_counts  cc_counts  authors  total   gw_frac  \\\n",
       "11     Showerthoughts       1897       1644     1340   3541  0.535724   \n",
       "1     climateskeptics       4374       4626      526   9000  0.486000   \n",
       "15         conspiracy       1338       1462      512   2800  0.477857   \n",
       "5          askscience       2887       3190     1958   6077  0.475070   \n",
       "16  explainlikeimfive       1090       1226      785   2316  0.470639   \n",
       "\n",
       "     cc_frac  aut_frac  \n",
       "11  0.464276  0.378424  \n",
       "1   0.514000  0.058444  \n",
       "15  0.522143  0.182857  \n",
       "5   0.524930  0.322198  \n",
       "16  0.529361  0.338946  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gwtop5 = keywords[(keywords[\"total\"] > 2000) & (keywords[\"aut_frac\"] > .01)].sort_values(\"gw_frac\", ascending = False).iloc[:5,]\n",
    "gwtop5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Where do these posts come from?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "domaincounts = pd.read_sql(\"\"\"SELECT domain, COUNT(domain) \n",
    "FROM gwtable\n",
    "GROUP BY domain\n",
    "ORDER BY COUNT(domain) DESC\n",
    "\"\"\",\n",
    "               con = engine)\n",
    "\n",
    "news = domaincounts[~(domaincounts[\"domain\"].str.contains(\"self.\")) &\n",
    "             ~(domaincounts[\"domain\"] == \"reddit.com\") & \n",
    "             ~(domaincounts[\"domain\"] == \"imgur.com\") & \n",
    "             ~(domaincounts[\"domain\"] == \"i.imgur.com\") & \n",
    "             ~(domaincounts[\"domain\"] == \"i.redd.it\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>COUNT(domain)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>2980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theguardian.com</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dailycaller.com</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>independent.co.uk</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wattsupwiththat.com</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dailymail.co.uk</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>thinkprogress.org</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>scientificamerican.com</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    domain  COUNT(domain)\n",
       "0              youtube.com           2980\n",
       "4          theguardian.com           1910\n",
       "10         dailycaller.com           1053\n",
       "11             nytimes.com           1024\n",
       "12      washingtonpost.com            939\n",
       "13       independent.co.uk            905\n",
       "15     wattsupwiththat.com            830\n",
       "16         dailymail.co.uk            725\n",
       "17       thinkprogress.org            664\n",
       "18  scientificamerican.com            648"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Next Steps:__\n",
    "\n",
    "Word frequency analysis of submissions containing the term \"global warming\" vs \"climate change\".\n",
    "\n",
    "- Are there certain words that seem most closely associated with each keyword?\n",
    "\n",
    "If time, produce a binary classifier.\n",
    "\n",
    "- After removing keywords, is it possible to guess which will be used based on other language in each submission? With what accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Implications:__\n",
    "\n",
    "A better understanding of the discourse surrounding climate change is essential to effectively communicating scientific research.\n",
    "\n",
    "- Seasonal patterns of interest can indicate when commuication is likely to be most effective, or when greater effort is needed.\n",
    "\n",
    "\n",
    "- Trends in use of language may suggest how different terms are being used or mischaracterized to drive a narrative, and how this information is disseminated."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
