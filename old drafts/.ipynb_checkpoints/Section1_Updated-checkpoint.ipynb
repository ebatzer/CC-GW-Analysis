{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "For many, Donald Trump's Twitter activity is a constant source of fascination. Whether you see this as evidence of his public communications genius or tempermental instability, @RealDonaldTrump's unfiltered stream of commentary on current events presents a rare opportunity to examine the thoughts and behavior of our country's highest elected official.\n",
    "\n",
    "Trump's Twitter is already under intense scrutiny; an upcoming Supreme Court decision on DACA, for example, may rest on whether Tweets are an official mouthpiece of the presidency. However, there appears to be less focus on examining trends of discourse in favor of immediate reactions that dominate news cycles. While gauging President Trump's response to current events is valuable, examining Trump's attention span and use of language over the long-term may yield new insights into the discourse surrounding key issues.\n",
    "\n",
    "As an environmental scientist, I'm particularly concerned how our President (and by virtue, the rest of the American public) thinks about climate change -- President Trump is a vocal proponent of climate skepticism. While his recent Twitter activity has been focused on more pressing concerns for his administration, climate change is a familiar topic; in the past 6 years, @RealDonaldTrump has expressed his opinion on climate science no less than 145 times.\n",
    "\n",
    "A closer look at the content of these Tweets suggests two key trends:\n",
    "\n",
    "__1. President Trump likes to draw attention to climate change when weather is cold__\n",
    "\n",
    "__2. President Trump prefers to use the term \"global warming\" over \"climate change\"__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">\n",
       "The concept of global warming was created by and for the Chinese in order to make U.S. \n",
       "manufacturing non-competitive.</p>&mdash; Donald J. Trump (@realDonaldTrump) \n",
       "<a href=\"https://twitter.com/realDonaldTrump/status/265895292191248385?ref_src=twsrc%5Etfw\">November 6, 2012</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<__main__.Tweet at 0x17b3515e8d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Tweet(object):\n",
    "    def __init__(self, embed_str=None):\n",
    "        self.embed_str = embed_str\n",
    "    def _repr_html_(self):\n",
    "        return self.embed_str\n",
    "    \n",
    "address = (\"\"\"\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">\n",
    "The concept of global warming was created by and for the Chinese in order to make U.S. \n",
    "manufacturing non-competitive.</p>&mdash; Donald J. Trump (@realDonaldTrump) \n",
    "<a href=\"https://twitter.com/realDonaldTrump/status/265895292191248385?ref_src=twsrc%5Etfw\">November 6, 2012</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\"\"\")\n",
    "\n",
    "Tweet(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">\n",
       "In the East, it could be the COLDEST New Year’s Eve on record. \n",
       "Perhaps we could use a little bit of that good old Global Warming that our Country, \n",
       "but not other countries, was going to pay TRILLIONS OF DOLLARS to protect against. Bundle up!\n",
       "</p>&mdash; Donald J. Trump (@realDonaldTrump) \n",
       "<a href=\"https://twitter.com/realDonaldTrump/status/946531657229701120?ref_src=twsrc%5Etfw\">\n",
       "December 29, 2017</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<__main__.Tweet at 0x17b3515ef28>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = (\"\"\"\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">\n",
    "In the East, it could be the COLDEST New Year’s Eve on record. \n",
    "Perhaps we could use a little bit of that good old Global Warming that our Country, \n",
    "but not other countries, was going to pay TRILLIONS OF DOLLARS to protect against. Bundle up!\n",
    "</p>&mdash; Donald J. Trump (@realDonaldTrump) \n",
    "<a href=\"https://twitter.com/realDonaldTrump/status/946531657229701120?ref_src=twsrc%5Etfw\">\n",
    "December 29, 2017</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\"\"\")\n",
    "\n",
    "Tweet(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scientific accuracy of these claims aside, this behavior highlights the difficulty in discussing climate change with an uninformed audience.\n",
    "\n",
    "In contrast to the immediate domestic concerns that are the foundation of Trump's poltical platform, climate change (like many ecological stressors) operates slowly and consistently - our frame of reference tends to shift faster than the environment. If it's difficult for a non-expert to make meaningful observations without looking at recorded data, communicating the significance of this phenomena can be nearly impossible.\n",
    "\n",
    "This __recency bias__, also known as \"ecological amnesia\" or the \"continuity effect\", is illustrated by the evidence Trump uses to support his arguments. Like many of us, President Trump appears to place greater emphasis on recent fluctuations than long-term trends. Seasonal fluctuations in weather are not a great predictor of broader climatic patterns, but we zero in on events that *feel* out of the ordinary, like a heavy winter snowstorm. \n",
    "\n",
    "His use of the term \"global warming\" instead of \"climate change\" also implies a deliberate choice of __misleading terminology__. While \"global warming\" is factually correct, science advocates have [cautioned against its use](https://www.nasa.gov/topics/earth/features/climate_by_any_other_name.html). The trend of increasing average global temperatures is just one piece of the effects of climate change, and may poorly reflect shifts in climatic patterns (such as greater frequency of extreme weather events like snowstorms and blizzards) that are relevant to most audiences. After priming readers with the term \"global warming\", President Trump is able to cast doubt on climate change by highlighting a particularly cold patch of weather in the Northeast US - even when these events are predicted by modern climate science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it's easy to dismiss @RealDonaldTrump's Twitter as politically motivated, the President is a savvy salesman, and his behavior may shed light on public preconceptions surrounding these issues. Given this behavior, one may ask:\n",
    "\n",
    "__1. Does interest in climate change vary seasonally? Do normal weather fluctuations seem to correlate with our ability to perceive the effects of environmental change?__\n",
    "\n",
    "__2. Are the terms \"climate change\" and \"global warming\" used in different contexts? Will authors seeking to promote a viewpoint, either as proponents or skeptics of climate science, be deliberate in their word choice?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Public Interest in Climate Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gauge public interest in climate science, Google Trends can offer a relatively unbiased, long-term (>10 year) dataset that captures general public interest in climate science. For this analysis, I've restricted myself to data on the search terms \"climate change\" and \"global warming\" within the United States \n",
    "\n",
    "To gauge public interest in climate science, I used two datasets:\n",
    "\n",
    "__1. Google Trends:__ Data on the frequency of searches for the terms \"climate change\" and \"global warming\" is likely to represent a relatively unbiased, long-term (>10 year) on general public interest in climate science.When accessing this data, I restricted search location to the United States. This data is standardized, such that the maximum frequency of search terms, aggregated in monthly intervals, is expressed as 100.\n",
    "\n",
    "__2. NOAA Climate Sensor Readings:__ An National Oceanic and Atmospheric Association data product, this dataset contains an average temperature (in farenheit) reading of climate sensors in the continental United States, aggregated in monthly intervals, from the 1970s to the present.\n",
    "\n",
    "Together, I expect these resources should be able to demonstrate correlations between search frequency and climate patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading and Cleaning Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebatz\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/googletrends.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b58c892bf084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Reading in dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mgtrends\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/googletrends.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Renaming columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'data/googletrends.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Calling required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib import dates\n",
    "\n",
    "import mpld3\n",
    "from mpld3 import plugins\n",
    "\n",
    "# Setting plot format \n",
    "%matplotlib inline\n",
    "\n",
    "# Reading in dataset\n",
    "gtrends = pd.read_csv(\"data/googletrends.csv\")\n",
    "\n",
    "# Renaming columns\n",
    "gtrends.columns = [\"month\", \"climate change\", \"global warming\"]\n",
    "\n",
    "# Converting numeric \"month\" to datetime\n",
    "gtrends[\"month\"] = gtrends[\"month\"] + \"/01\"\n",
    "gtrends[\"date_num\"] = pd.to_datetime(gtrends[\"month\"], yearfirst = True)\n",
    "\n",
    "# Creating a new variable, total number of searches, again standardized to 100 as maximum\n",
    "gtrends[\"total\"] = gtrends[\"climate change\"] + gtrends[\"global warming\"]\n",
    "gtrends[\"climate change\"] = (gtrends[\"climate change\"] / max(gtrends[\"total\"])) * 100\n",
    "gtrends[\"global warming\"] = (gtrends[\"global warming\"] / max(gtrends[\"total\"])) * 100\n",
    "gtrends[\"total\"] = (gtrends[\"total\"] / max(gtrends[\"total\"])) * 100\n",
    "\n",
    "# Adding weather data\n",
    "weather = pd.read_csv(\"data/NOAAweatherdata.csv\", skiprows = 4) \n",
    "\n",
    "# Converting \"Month\" and \"Year\" to datetime format\n",
    "weather[\"Month\"] = weather[\"Date\"] % 100\n",
    "weather[\"Year\"] = weather[\"Date\"].apply(str).apply(lambda x: x[:4])\n",
    "weather[\"Date\"] = weather[\"Year\"] + \"/\" + weather[\"Month\"].apply(str) + \"/01\"\n",
    "weather[\"date_num\"] = pd.to_datetime(weather[\"Date\"], yearfirst = True)\n",
    "\n",
    "# Binds datasets together\n",
    "gtrends = pd.merge(gtrends, weather, \"inner\")\n",
    "gtrends.rename(columns = {\"Value\": \"temp\"}, inplace = True)\n",
    "\n",
    "# Fit lowess smoothing line\n",
    "lowess = sm.nonparametric.lowess\n",
    "ys = lowess(gtrends[\"total\"], pd.to_numeric(gtrends[\"date_num\"]), frac = .3)[:,1]\n",
    "gtrends['lowess'] = ys\n",
    "\n",
    "# Compute residuals\n",
    "gtrends['resid'] = gtrends[\"total\"] - gtrends['lowess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there differences in the frequency of search terms for \"climate change\" and \"global warming\"?\n",
    "\n",
    "To visualize this data, I have used the MPLD3 library to produce interactive figures. Figures will contain interactive legends, hover text, or linked brushes where highlighting appears on all panels.\n",
    "\n",
    "This first figure shows a preference (on average) for the search term \"global warming\" over \"climate change\". Both large and small fluctuations appear to be present.\n",
    "\n",
    "- There appears to be a peak in searches for \"global warming\" in 2007-2008\n",
    "\n",
    "- Both search terms appear to show regular fluctuations within the overal trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MPLD3 Code Example\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14,7))\n",
    "\n",
    "fig.subplots_adjust(right=0.7)\n",
    "\n",
    "df = gtrends[[\"total\", \"climate change\", \"global warming\"]]\n",
    "\n",
    "for key, val in df.iteritems():\n",
    "    scatter = ax.scatter(val.index, val.values, label=key, s = 50)\n",
    "    #ax.plot(val.index, val.values, color = \"black\", alpha = .2, linewidth = .5)\n",
    "\n",
    "# define interactive legend\n",
    "handles, labels = ax.get_legend_handles_labels() # return lines and labels\n",
    "interactive_legend = plugins.InteractiveLegendPlugin(zip(handles, ax.collections), labels)\n",
    "\n",
    "ax.set_xlabel('Date', fontsize = 15)\n",
    "ax.set_ylabel('Search Term Frequency', fontsize = 15)\n",
    "ax.set_title('', fontsize = 20, weight = \"bold\")\n",
    "\n",
    "plt.xticks(np.linspace(0,168,8), \n",
    "           np.array(gtrends.month.apply(str))[np.linspace(0,168,8, dtype = \"int\").tolist()], \n",
    "           rotation = 90, fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "\n",
    "label_list = gtrends.total.append(gtrends[\"climate change\"])\n",
    "label_list = label_list.append(gtrends[\"global warming\"]).tolist()\n",
    "label_list = [round(i) for i in label_list]\n",
    "\n",
    "date_list = gtrends.month.tolist() * 3\n",
    "labeldf = pd.DataFrame(label_list, date_list)\n",
    "\n",
    "labels = np.array(['Relative Freq: {0} | Date: {1}'.format(i[1][0], i[0]) for i in labeldf.iterrows()])\n",
    "tooltip = mpld3.plugins.PointLabelTooltip(scatter, labels=labels)\n",
    "\n",
    "for collections, labels_chunk in zip(ax.collections, np.split(labels, 3)):\n",
    "    tooltip = mpld3.plugins.PointHTMLTooltip(collections, labels=labels_chunk)\n",
    "    mpld3.plugins.connect(fig, tooltip)\n",
    "\n",
    "mpld3.plugins.connect(fig, interactive_legend)\n",
    "\n",
    "mpld3.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does variation in search frequency correlate with seasonal temperature trends?\n",
    "\n",
    "To depict this information graphically, I first combined both search terms together to produce a \"total\" interest value, then fitted a LOWESS smoothing line to the data. Using the \"viridis\" colormap, I then colored datapoints by their respective mean temperature in the NOAA dataset.\n",
    "\n",
    "In this qualitative assessment, it's clear that regular seasonal fluctuations within the overall trend of Google search frequency appear to correlate with temperature patterns; __searches peak seasonally in cold weather, and decrease when weather is warm.__\n",
    "\n",
    "\n",
    "A secondary assessment of the same data presented above is to look at residuals associated with our LOWESS smoothing line. While a more complex time-series analysis may be more appropriate, we can still get a rough sense of these seasonal deviations.\n",
    "\n",
    "This figure confirms the assessment above, in which seasonal temperatures are correlated with search frequency. Interestingly, it appears that the strongest pattern is a decrease in searches in warm weather (negative residuals), rather than an increase in frqeuency during cold weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setting MPL Base Plot\n",
    "fig, ax = plt.subplots(1, 3, sharey = False, sharex = False, figsize = (14,7))\n",
    "fig.subplots_adjust(wspace=0.5, hspace = 0.5)\n",
    "\n",
    "colors = [ cm.viridis(x) for x in gtrends[\"temp\"] / max(gtrends[\"temp\"])]\n",
    "\n",
    "df = gtrends\n",
    "\n",
    "d_num = dates.date2num(df[\"date_num\"].tolist())\n",
    "\n",
    "# Adding horizontal lines\n",
    "ax[0].plot(d_num, df[\"lowess\"], linewidth = 2, color = \"black\")\n",
    "ax[0].plot(d_num, np.repeat(0, len(df.index)), color = \"white\")\n",
    "ax[2].plot(df.temp, np.repeat(0, len(df.index)), color = \"black\")\n",
    "ax[1].plot(df.Anomaly, np.repeat(0, len(df.index)), color = \"black\")\n",
    "\n",
    "# Adding points\n",
    "#points = ax[0].scatter(d_num, df[\"total\"], color = colors, s = 50)\n",
    "points = ax[0].scatter(d_num, df[\"total\"], color = colors, s = 50)\n",
    "points = ax[2].scatter(df.temp, df[\"resid\"], color = colors, s = 50)\n",
    "points = ax[1].scatter(df[\"Anomaly\"], df[\"resid\"], color = colors, s = 50)\n",
    "\n",
    "# Connecting MLPD3 linked brush\n",
    "plugins.connect(fig, plugins.LinkedBrush(points))\n",
    "\n",
    "# Axis labels\n",
    "ax[0].set_xlabel('Date', fontsize = 15)\n",
    "ax[0].set_ylabel('Total Search Frequency', fontsize = 15)\n",
    "\n",
    "ax[1].set_xlabel('SSTO Anomaly (F)', fontsize = 15)\n",
    "ax[1].set_ylabel('LOESS Residuals', fontsize = 15)\n",
    "\n",
    "ax[2].set_xlabel('Mean Monthly Temperature (F)', fontsize = 15)\n",
    "ax[2].set_ylabel('LOESS Residuals', fontsize = 15)\n",
    "\n",
    "dlabels = [\"2004/01/01\",\"2011/01/01\",\"2018/01/01\"]\n",
    "\n",
    "plt.sca(ax[0])\n",
    "plt.xticks(dates.date2num([datetime.datetime.strptime(x, \"%Y/%M/%d\") for x in dlabels]), dlabels)\n",
    "\n",
    "mpld3.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened in 2007?\n",
    "\n",
    "The above figures demonstrate the potential influence of seasonal climate patterns on yearly fluctuations in Google search activity, but do not explain the considerable peak in 2007-2008. This \"bump\" in search frequency is quite surprising - I would have assumed that climate science has become more mainstream, and that public interest would be steadily increasing over this interval.\n",
    "\n",
    "I think the most likely explanation for this peak is what I would call the \"Gore effect\":\n",
    "\n",
    "- __May 2006__ - \"An Inconvenient Truth\" released.\n",
    "- __February 2007__ - \"An Inconvenient Truth\" wins Academy Award for best documentary feature. \n",
    "- __October 2007__ - Al Gore and the IPCC wins Nobel Peace Prize.\n",
    "\n",
    "However, it's difficult to test this association quantitatively. There is a near infinite set of other, less-intuitive  explanatory events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPLD3 Code Example\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14,7))\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "\n",
    "from matplotlib import cm\n",
    "df = gtrends\n",
    "d_num = dates.date2num(df[\"date_num\"].tolist())\n",
    "\n",
    "plt.scatter(d_num, df[\"total\"], color = colors, s = 50)\n",
    "ax.plot(d_num, df[\"total\"], linewidth = 2, color = \"black\", alpha = .2)\n",
    "ax.plot(d_num, df[\"lowess\"], linewidth = 2, color = \"black\")\n",
    "\n",
    "ax.set_ylabel('Google Trends Frequency', fontsize = 15)\n",
    "\n",
    "gore_lines = [\"2006-05-24\",\"2007-02-26\",\"2007-10-12\"]\n",
    "labels = ['\"An Incovenient Truth\" Released', 'AIT Wins Best Documentary', 'Al Gore and IPCC win Nobel']\n",
    "\n",
    "g_num = dates.date2num(pd.to_datetime(gore_lines, yearfirst=True).tolist())\n",
    "\n",
    "for d,l in zip(g_num, labels):\n",
    "    ax.plot(np.repeat(d, 10), np.linspace(0,100,10), \n",
    "            linewidth = 2, color = \"red\", alpha = .2)\n",
    "    \n",
    "    ax.annotate(l, xy=(d,80), xytext=(d + 40, 120),\n",
    "               rotation = 90, fontsize = 15)\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "dlabels = [\"2004/01/01\",\"2006/01/01\",\"2008/01/01\",\"2010/01/01\",\"2012/01/01\",\"2014/01/01\",\"2016/01/01\",\"2018/01/01\"]\n",
    "plt.xticks(dates.date2num([datetime.datetime.strptime(x, \"%Y/%M/%d\") for x in dlabels]), dlabels)\n",
    "\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
